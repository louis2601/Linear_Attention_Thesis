{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-04T13:32:29.069016Z",
     "start_time": "2025-12-04T13:32:26.138016Z"
    }
   },
   "source": "pip install torch transformers bitsandbytes peft trl datasets accelerate scipy",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (5.0.0.dev0)\n",
      "Requirement already satisfied: bitsandbytes in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (0.48.2)\n",
      "Requirement already satisfied: peft in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: trl in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: datasets in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: accelerate in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: scipy in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (1.16.3)\n",
      "Requirement already satisfied: filelock in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.0.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: typer-slim in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.0.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.0.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.0.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: anyio in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: psutil in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from typer-slim->transformers) (8.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:33:10.908959Z",
     "start_time": "2025-12-04T13:32:37.870715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer"
   ],
   "id": "3843962c81971efa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup and Config",
   "id": "bd4351a493902b1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:33:34.528572Z",
     "start_time": "2025-12-04T13:33:16.045416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_ID = \"state-spaces/mamba-1.4b-hf\"\n",
    "OUTPUT_DIR = \"./babilong_mamba_finetune\"\n",
    "\n",
    "# Task Setup\n",
    "TASK_NAME = \"qa1\"\n",
    "SPLIT_LENGTH = \"0k\"  # Ideal f√ºr den Start auf der 3080\n",
    "\n",
    "# QLoRA Config (Speicher sparen)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # RTX 3080 Feature\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "# 2. Modell laden mit der Config\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config, # <--- DAS IST ENTSCHEIDEND\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True # Mamba braucht das oft noch\n",
    ")"
   ],
   "id": "e43fb9ba9511672b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b87309ac2a874316954a4fb427767465"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:33:38.744752Z",
     "start_time": "2025-12-04T13:33:38.741688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LoRA Config f√ºr MAMBA\n",
    "# Mamba hat spezifische Layer-Namen. 'all-linear' ist hier der sicherste Weg,\n",
    "# um 'in_proj', 'out_proj', 'x_proj' und 'dt_proj' automatisch zu erwischen.\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"in_proj\", \"x_proj\", \"dt_proj\"]\n",
    ")"
   ],
   "id": "a158b8104dfe7fe1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:33:43.911925Z",
     "start_time": "2025-12-04T13:33:43.252604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_ID = \"state-spaces/mamba-1.4b-hf\"\n",
    "\n",
    "print(f\"Lade Tokenizer f√ºr {MODEL_ID}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Fix f√ºr Mamba / GPT-NeoX Tokenizer:\n",
    "# Da kein 'pad_token' definiert ist, nutzen wir das End-of-Sentence Token.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# F√ºr Training mit SFTTrainer ist \"right\" padding Standard\n",
    "tokenizer.padding_side = \"right\" \n",
    "\n",
    "print(f\"Tokenizer geladen. Pad Token ID: {tokenizer.pad_token_id}\")"
   ],
   "id": "a59ab2010b4b6e08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Tokenizer f√ºr state-spaces/mamba-1.4b-hf...\n",
      "Tokenizer geladen. Pad Token ID: 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "3b7649b802146d21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:33:53.796326Z",
     "start_time": "2025-12-04T13:33:48.204356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# ==========================================\n",
    "# DATASET LADEN & FORMATIEREN\n",
    "# ==========================================\n",
    "\n",
    "print(f\"Lade BABILong {TASK_NAME} ({SPLIT_LENGTH})...\")\n",
    "\n",
    "# 1. Laden des spezifischen Splits (z.B. split='qa1')\n",
    "# Das l√§dt NUR die Daten f√ºr diesen Task. Wir m√ºssen nicht mehr filtern.\n",
    "dataset = load_dataset(\"RMT-team/babilong\", SPLIT_LENGTH, split=TASK_NAME)\n",
    "\n",
    "# DEBUG: Zeige uns, welche Spalten wirklich da sind (vermeidet KeyErrors in der Zukunft)\n",
    "print(f\"Verf√ºgbare Spalten: {dataset.column_names}\")\n",
    "\n",
    "# 2. Optional: Nur einen kleinen Teil zum Testen nutzen (Auskommentieren f√ºr echtes Training)\n",
    "# dataset = dataset.select(range(100)) \n",
    "\n",
    "def formatting_prompts_func(example):\n",
    "    \"\"\"\n",
    "    Formatierungsfunktion V3 (Final Fix).\n",
    "    Unterscheidet sauber zwischen Batch (Liste) und Single (String),\n",
    "    damit der SFTTrainer nicht √ºber Datentypen stolpert.\n",
    "    \"\"\"\n",
    "    # 1. Pr√ºfen: Haben wir einen Batch (Liste von Inputs) oder ein einzelnes Item?\n",
    "    # Wir pr√ºfen 'input', da dies im Dataset vorhanden ist.\n",
    "    is_batch = isinstance(example['input'], list)\n",
    "    \n",
    "    if is_batch:\n",
    "        # === BATCH MODUS ===\n",
    "        output_texts = []\n",
    "        for i in range(len(example['input'])):\n",
    "            text = (\n",
    "                f\"Context: {example['input'][i]}\\n\\n\"\n",
    "                f\"Question: {example['question'][i]}\\n\\n\"\n",
    "                f\"Answer: {example['target'][i]}\"\n",
    "            )\n",
    "            output_texts.append(text)\n",
    "        return output_texts # R√ºckgabe: Liste von Strings\n",
    "        \n",
    "    else:\n",
    "        # === SINGLE SAMPLE MODUS ===\n",
    "        # Hier d√ºrfen wir KEINE Liste zur√ºckgeben, sondern nur den nackten String!\n",
    "        text = (\n",
    "            f\"Context: {example['input']}\\n\\n\"\n",
    "            f\"Question: {example['question']}\\n\\n\"\n",
    "            f\"Answer: {example['target']}\"\n",
    "        )\n",
    "        return text # R√ºckgabe: Ein einzelner String\n",
    "\n",
    "print(\"Dataset erfolgreich geladen und bereit.\")"
   ],
   "id": "8048b40bf7106148",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade BABILong qa1 (0k)...\n",
      "Verf√ºgbare Spalten: ['target', 'input', 'question']\n",
      "Dataset erfolgreich geladen und bereit.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:34:03.870762Z",
     "start_time": "2025-12-04T13:34:03.861615Z"
    }
   },
   "cell_type": "code",
   "source": "dataset[0]",
   "id": "1ce639c8f0d02ec9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 'bathroom',\n",
       " 'input': 'John travelled to the hallway. Mary journeyed to the bathroom. Daniel went back to the bathroom. John moved to the bedroom.',\n",
       " 'question': 'Where is Mary? '}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Config and start",
   "id": "3d3775ddf30e65a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:44:21.966245Z",
     "start_time": "2025-12-04T13:35:04.186101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "OUTPUT_DIR = \"./babilong_mamba_finetune\"\n",
    "\n",
    "# 1. Die Konfiguration (Hier kommen jetzt die Parameter rein!)\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    #max_seq_length=4096,             # <--- HIER muss es stehen\n",
    "    packing=False,                   # <--- HIER muss es stehen\n",
    "    dataset_text_field=\"text\",       # Dummy-Feld (wird ignoriert wegen formatting_func, muss aber oft da sein)\n",
    "    \n",
    "    # Standard Training Arguments\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    warmup_ratio=0.03,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    group_by_length=False,\n",
    "    disable_tqdm=False,  # <--- Das erzwingt den Ladebalken (ist aber meist Default)\n",
    ")\n",
    "\n",
    "print(\"Initialisiere SFTTrainer...\")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    #tokenizer=tokenizer,\n",
    "    args=sft_config,       # <--- Wir √ºbergeben die Config hier\n",
    "    # WICHTIG: Hier unten DARF KEIN max_seq_length oder packing mehr stehen!\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starte Training...\")\n",
    "trainer.train()\n",
    "\n",
    "print(f\"Training beendet. Speichere Adapter in {OUTPUT_DIR}...\")\n",
    "trainer.model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)"
   ],
   "id": "6b3093604c6d52af",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisiere SFTTrainer...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc2df56d14004ba08e650356dfb2915e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c13d7e9c28704ce79ebb4c22295e437c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6d1e37dfc5341d899437a3b87f7a2c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92a82091c13c4a0ba720e9b3decefe6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starte Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 08:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>9.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.585200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training beendet. Speichere Adapter in ./babilong_mamba_finetune...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./babilong_mamba_finetune\\\\tokenizer_config.json',\n",
       " './babilong_mamba_finetune\\\\special_tokens_map.json',\n",
       " './babilong_mamba_finetune\\\\tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "id": "d4aa5962593b8c9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
